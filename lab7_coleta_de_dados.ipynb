{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj8o+eF6u0BgXfcT9pnxcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaCaRego/JaCaRego/blob/main/lab7_coleta_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLmuqimQCZWZ",
        "outputId": "91a64301-a550-4f77-b871-b64117ccf4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Título': 'A Light in the ...', 'Preço': '£51.77'}\n",
            "{'Título': 'Tipping the Velvet', 'Preço': '£53.74'}\n",
            "{'Título': 'Soumission', 'Preço': '£50.10'}\n",
            "{'Título': 'Sharp Objects', 'Preço': '£47.82'}\n",
            "{'Título': 'Sapiens: A Brief History ...', 'Preço': '£54.23'}\n",
            "{'Título': 'The Requiem Red', 'Preço': '£22.65'}\n",
            "{'Título': 'The Dirty Little Secrets ...', 'Preço': '£33.34'}\n",
            "{'Título': 'The Coming Woman: A ...', 'Preço': '£17.93'}\n",
            "{'Título': 'The Boys in the ...', 'Preço': '£22.60'}\n",
            "{'Título': 'The Black Maria', 'Preço': '£52.15'}\n",
            "{'Título': 'Starving Hearts (Triangular Trade ...', 'Preço': '£13.99'}\n",
            "{'Título': \"Shakespeare's Sonnets\", 'Preço': '£20.66'}\n",
            "{'Título': 'Set Me Free', 'Preço': '£17.46'}\n",
            "{'Título': \"Scott Pilgrim's Precious Little ...\", 'Preço': '£52.29'}\n",
            "{'Título': 'Rip it Up and ...', 'Preço': '£35.02'}\n",
            "{'Título': 'Our Band Could Be ...', 'Preço': '£57.25'}\n",
            "{'Título': 'Olio', 'Preço': '£23.88'}\n",
            "{'Título': 'Mesaerion: The Best Science ...', 'Preço': '£37.59'}\n",
            "{'Título': 'Libertarianism for Beginners', 'Preço': '£51.33'}\n",
            "{'Título': \"It's Only the Himalayas\", 'Preço': '£45.17'}\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "\n",
        "url = 'https://books.toscrape.com/'\n",
        "requisicao = requests.get(url)\n",
        "requisicao.encoding = 'utf-8'\n",
        "\n",
        "extracao = BeautifulSoup(requisicao.text, 'html.parser')\n",
        "\n",
        "contar_livros = 0\n",
        "catalogo = []\n",
        "\n",
        "for artigo in extracao.find_all('article', class_='product_pod'):\n",
        "    livro = {}\n",
        "    for h3 in artigo.find_all('h3'):\n",
        "        titulo = h3.text\n",
        "        livro['Título'] = titulo\n",
        "    for p in artigo.find_all('p', class_='price_color'):\n",
        "        preco = p.text\n",
        "        livro['Preço'] = preco\n",
        "    contar_livros += 1\n",
        "    catalogo.append(livro)\n",
        "    print(livro)\n",
        "\n",
        "\n",
        "print(contar_livros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e14ad3"
      },
      "source": [
        "Este código Python usa as bibliotecas `requests` e `BeautifulSoup` para fazer web scraping no site \"https://books.toscrape.com/\" e extrair informações sobre os livros na primeira página.\n",
        "\n",
        "Aqui está um detalhamento de cada parte:\n",
        "\n",
        "1.  **Importação de bibliotecas**:\n",
        "    *   `import requests`: Importa a biblioteca `requests` para fazer requisições HTTP (como obter o conteúdo de uma página web).\n",
        "    *   `from bs4 import BeautifulSoup`: Importa a classe `BeautifulSoup` da biblioteca `bs4` (Beautiful Soup) para analisar o conteúdo HTML.\n",
        "    *   `import pandas as pd`: Importa a biblioteca `pandas` (embora não esteja sendo usada ativamente neste código específico, ela foi importada, talvez para uso posterior).\n",
        "    *   `requests.packages.urllib3.disable_warnings()`: Desabilita avisos relacionados a requisições (útil para evitar mensagens de aviso no output).\n",
        "\n",
        "2.  **Definindo a URL e fazendo a requisição**:\n",
        "    *   `url = 'https://books.toscrape.com/'`: Define a URL do site a ser raspado.\n",
        "    *   `requisicao = requests.get(url)`: Faz uma requisição GET para a URL e armazena a resposta na variável `requisicao`.\n",
        "    *   `requisicao.encoding = 'utf-8'`: Define a codificação da resposta para UTF-8 para garantir que caracteres especiais sejam exibidos corretamente.\n",
        "\n",
        "3.  **Analisando o conteúdo HTML**:\n",
        "    *   `extracao = BeautifulSoup(requisicao.text, 'html.parser')`: Cria um objeto `BeautifulSoup` passando o conteúdo HTML da resposta (`requisicao.text`) e especificando o parser a ser usado (`'html.parser'`). Isso transforma o HTML em uma estrutura de dados que pode ser facilmente navegada.\n",
        "\n",
        "4.  **Inicializando variáveis**:\n",
        "    *   `contar_livros = 0`: Inicializa uma variável para contar o número de livros encontrados.\n",
        "    *   `catalogo = []`: Inicializa uma lista vazia que armazenará os dados de cada livro (título e preço) como dicionários.\n",
        "\n",
        "5.  **Iterando sobre os livros**:\n",
        "    *   `for artigo in extracao.find_all('article', class_='product_pod'):`: Este é o loop principal. Ele encontra todas as tags `<article>` com a classe `product_pod` na página HTML e itera sobre cada uma delas. Cada tag `<article>` representa um livro individual.\n",
        "    *   `livro = {}`: Dentro do loop principal, um dicionário vazio chamado `livro` é criado para armazenar as informações (título e preço) do livro atual.\n",
        "    *   `for h3 in artigo.find_all('h3'):`: Dentro do loop do artigo, encontra todas as tags `<h3>` dentro do artigo atual. Para este site, há uma tag `<h3>` por livro que contém o título.\n",
        "    *   `titulo = h3.text`: Extrai o texto (o título do livro) da tag `<h3>` encontrada e o armazena na variável `titulo`.\n",
        "    *   `livro['Título'] = titulo`: Adiciona uma entrada ao dicionário `livro` com a chave 'Título' e o valor da variável `titulo`.\n",
        "    *   `for p in artigo.find_all('p', class_='price_color'):`: Encontra todas as tags `<p>` com a classe `price_color` dentro do artigo atual. Para este site, há uma tag `<p>` por livro que contém o preço.\n",
        "    *   `preco = p.text`: Extrai o texto (o preço do livro) da tag `<p>` encontrada e o armazena na variável `preco`.\n",
        "    *   `livro['Preço'] = preco`: Adiciona uma entrada ao dicionário `livro` com a chave 'Preço' e o valor da variável `preco`.\n",
        "    *   `contar_livros += 1`: Incrementa a variável `contar_livros` em 1 para cada livro processado.\n",
        "    *   `catalogo.append(livro)`: Adiciona o dicionário `livro` (contendo o título e preço do livro atual) à lista `catalogo`.\n",
        "\n",
        "6.  **Imprimindo o resultado**:\n",
        "    *   `print(contar_livros)`: Após o loop principal terminar, imprime o valor final da variável `contar_livros`, que representa o total de livros encontrados na primeira página.\n",
        "\n",
        "Em resumo, o código acessa uma página web, encontra cada seção que representa um livro, extrai o título e o preço de cada livro e armazena essas informações em uma lista de dicionários, além de contar quantos livros foram encontrados.\n",
        "\n",
        "Se você tiver mais perguntas sobre partes específicas do código, é só perguntar!"
      ]
    }
  ]
}