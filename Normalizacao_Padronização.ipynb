{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4baSiRC51MJ/jSH8aH+/x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaCaRego/JaCaRego/blob/main/Normalizacao_Padroniza%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c85b24d7"
      },
      "source": [
        "## NORMALIZAÇÃO E PADRONIZAÇÃO\n",
        "\n",
        "Este código realiza o *escalonamento de dados* (data scaling) em um DataFrame do pandas, aplicando três métodos diferentes às colunas 'idade' e 'salário':\n",
        "\n",
        "1.  **Normalização (MinMaxScaler)**: Transforma os dados para uma escala entre 0 e 1, ou -1 e 1. Isso garante que todos os valores das colunas sejam proporcionais dentro desse intervalo, sendo útil para algoritmos que dependem de distâncias ou são sensíveis à magnitude dos valores.\n",
        "2.  **Padronização (StandardScaler)**: Transforma os dados para que tenham uma média de 0 e um desvio padrão de 1. É útil quando a distribuição dos dados se aproxima de uma distribuição normal e para algoritmos que assumem dados centralizados.\n",
        "3.  **RobustScaler**: Similar ao StandardScaler, mas é mais robusto a *outliers* (valores atípicos) por usar a mediana e o Intervalo Interquartil (IQR) para escalar os dados.\n",
        "\n",
        "### Função Principal:\n",
        "\n",
        "*   **Preparação de Dados**: Carrega dados de um arquivo CSV (`clientes-v2-tratados.csv`).\n",
        "*   **Seleção de Features**: Foca nas colunas 'idade' e 'salário'.\n",
        "*   **Aplicação de Escalonamento**: Cria novas colunas para cada método de escalonamento aplicado.\n",
        "*   **Análise Pós-Escalonamento**: Imprime estatísticas (mínimo, máximo, média, desvio padrão) para cada coluna escalonada, permitindo comparar o efeito de cada técnica. A normalização é fundamental para tornar variáveis com escalas muito diferentes comparáveis e evitar que uma domine a análise ou o modelo de machine learning, como no exemplo de um sistema de crédito."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b5d84c9"
      },
      "source": [
        "## Detalhamento das Fórmulas de Escalonamento e Definição de Termos\n",
        "\n",
        "Cada um dos escaladores possui uma fórmula matemática específica para transformar os dados, garantindo que o escalonamento seja aplicado de forma consistente. Além disso, incluímos as definições dos termos técnicos utilizados.\n",
        "\n",
        "### 1. MinMaxScaler (Normalização)\n",
        "\n",
        "O MinMaxScaler transforma as *features* (características ou atributos, as colunas ou variáveis independentes em um conjunto de dados) escalando cada *feature* individualmente para um determinado intervalo, geralmente entre 0 e 1, ou -1 e 1. Ele faz isso removendo o mínimo e dividindo pelo máximo menos o mínimo.\n",
        "\n",
        "**Fórmula:**\n",
        "$$ X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}} $$\n",
        "Onde:\n",
        "*   $X$ é o valor original do dado.\n",
        "*   $X_{min}$ é o valor mínimo da *feature*.\n",
        "*   $X_{max}$ é o valor máximo da *feature*.\n",
        "*   $X_{norm}$ é o valor normalizado.\n",
        "\n",
        "**Explicação:**\n",
        "Esta normalização é útil para algoritmos que não assumem uma distribuição específica para os dados, como redes neurais e algoritmos baseados em distância (**KNN** - *k-Nearest Neighbors*, um algoritmo que classifica um ponto de dados com base na maioria das classes de seus 'k' vizinhos mais próximos, e **SVM** - *Support Vector Machine*, um algoritmo que busca um hiperplano ótimo para separar classes), onde a escala dos dados pode influenciar diretamente a computação das distâncias. Ela comprime todos os dados para dentro de um intervalo fixo, mantendo a forma original da distribuição dos dados.\n",
        "\n",
        "### 2. StandardScaler (Padronização)\n",
        "\n",
        "O StandardScaler padroniza as *features* (características ou atributos) removendo a média e escalando para a variância da unidade. O resultado é que a distribuição dos dados terá uma média igual a 0 e um desvio padrão igual a 1. Isso é útil para *features* que seguem uma distribuição normal (gaussiana) ou que precisam ser centralizadas.\n",
        "\n",
        "**Fórmula:**\n",
        "$$ X_{pad} = \\frac{X - \\mu}{\\sigma} $$\n",
        "Onde:\n",
        "*   $X$ é o valor original do dado.\n",
        "*   $\\mu$ é a média da *feature*.\n",
        "*   $\\sigma$ é o desvio padrão da *feature*.\n",
        "*   $X_{pad}$ é o valor padronizado.\n",
        "\n",
        "**Explicação:**\n",
        "Essa padronização é particularmente importante para algoritmos que assumem que os dados são centralizados em 0 e têm uma variância semelhante, como **Regressão Linear** (um algoritmo de aprendizado supervisionado que modela a relação linear entre variáveis), **Regressão Logística** (um algoritmo de classificação usado para prever a probabilidade de um evento), **SVMs** (Máquinas de Vetores de Suporte, um algoritmo que busca um hiperplano ótimo para separar classes) com certos *kernels* (funções que transformam dados de baixa dimensão em um espaço de alta dimensão, facilitando a separação ou detecção de padrões não-lineares) e Redes Neurais. Ela lida bem com *outliers*, pois o cálculo da média e do desvio padrão é sensível a eles, mas o objetivo é trazer a distribuição para um formato padrão.\n",
        "\n",
        "### 3. RobustScaler\n",
        "\n",
        "O RobustScaler escala os *features* (características ou atributos) usando estatísticas que são robustas a *outliers* (valores atípicos ou discrepantes, que se desviam significativamente de outras observações). Ele remove a mediana e escala os dados usando o intervalo interquartil (IQR), que é a diferença entre o terceiro quartil (Q3) e o primeiro quartil (Q1).\n",
        "\n",
        "**Fórmula:**\n",
        "$$ X_{rob} = \\frac{X - Mediana}{IQR} $$\n",
        "Onde:\n",
        "*   $X$ é o valor original do dado.\n",
        "*   $Mediana$ é a mediana da *feature*.\n",
        "*   $IQR$ é o intervalo interquartil da *feature* ($Q_3 - Q_1$).\n",
        "*   $X_{rob}$ é o valor escalonado pelo RobustScaler.\n",
        "\n",
        "**Explicação:**\n",
        "Ao contrário do StandardScaler, o RobustScaler utiliza a mediana e o IQR, que são estatísticas menos afetadas por valores extremos (*outliers*). Isso o torna a escolha ideal quando o seu conjunto de dados contém muitos *outliers* e você não quer que eles influenciem a transformação de forma significativa. É especialmente útil em cenários onde a distribuição dos dados é assimétrica ou possui uma cauda longa devido a *outliers*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC8lZRcS7nLE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df = pd.read_csv('dados/clientes-v2-tratados.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "#Pode usar qualquer um do dois\n",
        "#df = df.drop(['data', 'estado', 'nivel_educacao', 'numero_filhos', 'estado_civil', 'area_atuacao'], axis=1)\n",
        "df = df[['idade', 'salario']]\n",
        "\n",
        "# Normalização - MinMax/scaler.\n",
        "scaler = MinMaxScaler()\n",
        "df['idadeMinMaxScaler'] = scaler.fit_transform(df[['idade']])\n",
        "df['salarioMinMaxScaler'] = scaler.fit_transform(df[['salario']])\n",
        "\n",
        "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "df['idadeMinMaxScaler_mm'] = min_max_scaler.fit_transform(df[['idade']])\n",
        "df['salarioMinMaxScaler_mm'] = min_max_scaler.fit_transform(df[['salario']])\n",
        "\n",
        "# Padronização - StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df['idadeStandardScaler'] = scaler.fit_transform(df[['idade']])\n",
        "df['salarioStandardScaler'] = scaler.fit_transform(df[['salario']])\n",
        "\n",
        "# Padronização RobustScaler\n",
        "scaler = RobustScaler()\n",
        "df['idadeRobustScaler'] = scaler.fit_transform(df[['idade']])\n",
        "df['salarioRobustScaler'] = scaler.fit_transform(df[['salario']])\n",
        "\n",
        "print(df.head(15))\n",
        "\n",
        "print('MinMaxScaler (De 0 a 1):')\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeMinMaxScaler'].min(), df['idadeMinMaxScaler'].max(), df['idadeMinMaxScaler'].mean(), df['idadeMinMaxScaler'].std()))\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioMinMaxScaler'].min(), df['salarioMinMaxScaler'].max(), df['salarioMinMaxScaler'].mean(), df['salarioMinMaxScaler'].std()))\n",
        "\n",
        "print('\\nMinMaxScaler (De -1 a 1):')\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeMinMaxScaler_mm'].min(), df['idadeMinMaxScaler_mm'].max(), df['idadeMinMaxScaler'].mean(), df['idadeMinMaxScaler'].std()))\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioMinMaxScaler_mm'].min(), df['salarioMinMaxScaler_mm'].max(), df['salarioMinMaxScaler_mm'].mean(), df['salarioMinMaxScaler_mm'].std()))\n",
        "\n",
        "print('\\nStandardScaler (Ajuste a média a 0 e desvio padrão a 1):')\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.18f} Std: {:.4f}'.format(df['idadeStandardScaler'].min(), df['idadeStandardScaler'].max(), df['idadeStandardScaler'].mean(), df['idadeStandardScaler'].std()))\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.18f} Std: {:.4f}'.format(df['salarioStandardScaler'].min(), df['salarioStandardScaler'].max(), df['salarioStandardScaler'].mean(), df['salarioStandardScaler'].std()))\n",
        "\n",
        "print('\\nRobustScaler (Ajuste a média e IQR):')\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeRobustScaler'].min(), df['idadeRobustScaler'].max(), df['idadeRobustScaler'].mean(), df['idadeRobustScaler'].std()))\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioRobustScaler'].min(), df['salarioRobustScaler'].max(), df['salarioRobustScaler'].mean(), df['salarioRobustScaler'].std()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2dd617d"
      },
      "source": [
        "### **Importação de Bibliotecas e Configuração Inicial**\n",
        "\n",
        "Esta seção importa as bibliotecas necessárias para manipulação de dados (`pandas`) e para o escalonamento (`sklearn.preprocessing`).\n",
        "\n",
        "*   `pandas as pd`: Essencial para trabalhar com DataFrames, que são estruturas de dados tabulares.\n",
        "*   `RobustScaler`, `MinMaxScaler`, `StandardScaler` (de `sklearn.preprocessing`): Classes que implementam os diferentes métodos de escalonamento de dados.\n",
        "\n",
        "As configurações `pd.set_option` ajustam a forma como o pandas exibe os DataFrames, garantindo que colunas e largura não sejam truncadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9311341a"
      },
      "source": [
        "### **Carregamento e Seleção de Dados**\n",
        "\n",
        "Primeiro, o código carrega o arquivo `clientes-v2-tratados.csv` em um DataFrame chamado `df`.\n",
        "\n",
        "Em seguida, são selecionadas apenas as colunas `'idade'` e `'salario'` para a aplicação dos métodos de escalonamento, descartando as outras features para simplificar a demonstração. A visualização inicial (`df.head()`) mostra as primeiras linhas do DataFrame antes do processamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6870b277"
      },
      "source": [
        "### **Normalização com MinMaxScaler (Intervalo [0, 1])**\n",
        "\n",
        "Aqui, o `MinMaxScaler` é aplicado para normalizar as colunas `'idade'` e `'salario'` para um intervalo entre 0 e 1. Isso significa que o valor mínimo de cada coluna se tornará 0 e o valor máximo se tornará 1, com os demais valores escalados proporcionalmente.\n",
        "\n",
        "*   `scaler = MinMaxScaler()`: Cria uma instância do MinMaxScaler.\n",
        "*   `scaler.fit_transform(df[['coluna']])`: Calcula os parâmetros de escalonamento (mínimo e máximo da coluna) e aplica a transformação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "581b4478"
      },
      "source": [
        "### **Normalização com MinMaxScaler (Intervalo [-1, 1])**\n",
        "\n",
        "Similar ao passo anterior, mas desta vez o `MinMaxScaler` é configurado para escalar os dados para o intervalo de -1 a 1. Isso é feito ao especificar `feature_range=(-1, 1)` durante a instanciação do scaler.\n",
        "\n",
        "*   `min_max_scaler = MinMaxScaler(feature_range=(-1, 1))`: Cria uma instância com o intervalo desejado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d285bb9"
      },
      "source": [
        "### **Padronização com StandardScaler**\n",
        "\n",
        "O `StandardScaler` transforma os dados para que tenham uma média de 0 e um desvio padrão de 1. Este método é útil quando os dados seguem uma distribuição normal ou quando o algoritmo de Machine Learning assume esta característica.\n",
        "\n",
        "*   `scaler = StandardScaler()`: Cria uma instância do StandardScaler.\n",
        "*   `scaler.fit_transform(df[['coluna']])`: Calcula a média ($\\mu$) e o desvio padrão ($\\sigma$) da coluna e aplica a fórmula $X_{pad} = \\frac{X - \\mu}{\\sigma}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "416601fe"
      },
      "source": [
        "### **Padronização com RobustScaler**\n",
        "\n",
        "O `RobustScaler` é uma alternativa ao `StandardScaler` que é menos sensível a *outliers*. Ele escala os dados usando a mediana e o Intervalo Interquartil (IQR), em vez da média e do desvio padrão.\n",
        "\n",
        "*   `scaler = RobustScaler()`: Cria uma instância do RobustScaler.\n",
        "*   `scaler.fit_transform(df[['coluna']])`: Calcula a mediana e o IQR da coluna e aplica a fórmula $X_{rob} = \\frac{X - Mediana}{IQR}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b63529d8"
      },
      "source": [
        "### **Visualização dos Dados Escalonados e Padronizados**\n",
        "\n",
        "Após a aplicação de todos os escalonadores, `print(df.head(15))` exibe as primeiras 15 linhas do DataFrame. Agora, o DataFrame inclui as colunas originais e todas as novas colunas com os dados transformados por cada método, permitindo uma comparação visual inicial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcf687d1"
      },
      "source": [
        "### **Análise Estatística dos Dados Transformados**\n",
        "\n",
        "Por fim, o código calcula e imprime estatísticas descritivas (mínimo, máximo, média e desvio padrão) para cada uma das colunas que foram escalonadas. Isso ajuda a verificar se os escalonadores funcionaram como esperado:\n",
        "\n",
        "*   **MinMaxScaler (0 a 1):** Mínimo próximo de 0, máximo próximo de 1.\n",
        "*   **MinMaxScaler (-1 a 1):** Mínimo próximo de -1, máximo próximo de 1.\n",
        "*   **StandardScaler:** Média próxima de 0, desvio padrão próximo de 1.\n",
        "*   **RobustScaler:** Média próxima de 0 (mediana zero), e desvio padrão que reflete a escala do IQR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2cb085"
      },
      "source": [
        "```python\n",
        "import pandas as pd # Importa a biblioteca pandas, fundamental para manipulação e análise de dados tabulares (DataFrames) em Python.\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler # Importa classes específicas do módulo `preprocessing` da biblioteca `scikit-learn` (sklearn).\n",
        "                                                                           # - `RobustScaler`: Usado para escalar dados de forma robusta a *outliers*, usando mediana e IQR.\n",
        "                                                                           # - `MinMaxScaler`: Usado para normalizar dados para um intervalo fixo (ex: [0, 1] ou [-1, 1]).\n",
        "                                                                           # - `StandardScaler`: Usado para padronizar dados, transformando-os para ter média 0 e desvio padrão 1.\n",
        "\n",
        "\n",
        "pd.set_option('display.width', None) # Configura uma opção de exibição do pandas para que as saídas de DataFrames não sejam truncadas horizontalmente no console ou em ambientes interativos.\n",
        "pd.set_option('display.max_colwidth', None) # Configura uma opção de exibição do pandas para que o conteúdo das colunas em DataFrames não seja truncado verticalmente.\n",
        "\n",
        "df = pd.read_csv('dados/clientes-v2-tratados.csv') # Carrega dados de um arquivo CSV ('clientes-v2-tratados.csv') para um objeto DataFrame do pandas, chamado 'df'.\n",
        "\n",
        "print(df.head()) # Exibe as cinco primeiras linhas do DataFrame 'df', permitindo uma visualização rápida da estrutura e dos dados iniciais.\n",
        "\n",
        "#Pode usar qualquer um do dois\n",
        "#df = df.drop(['data', 'estado', 'nivel_educacao', 'numero_filhos', 'estado_civil', 'area_atuacao'], axis=1) # Esta linha (comentada) mostra como remover múltiplas colunas de um DataFrame, caso não sejam necessárias para a análise atual.\n",
        "df = df[['idade', 'salario']] # Seleciona apenas as colunas 'idade' e 'salario' do DataFrame e reatribui o resultado a 'df', efetivamente descartando as outras colunas para a análise de escalonamento.\n",
        "\n",
        "# Normalização - MinMax/scaler. (Escalonamento para um intervalo)\n",
        "scaler = MinMaxScaler() # Cria uma instância do MinMaxScaler. Por padrão, ele escala os dados para o intervalo [0, 1].\n",
        "df['idadeMinMaxScaler'] = scaler.fit_transform(df[['idade']]) # Aplica o MinMaxScaler à coluna 'idade'. `fit_transform` primeiro calcula os valores mínimos e máximos da coluna ('fit') e depois usa esses valores para escalar os dados ('transform'), armazenando o resultado em uma nova coluna.\n",
        "df['salarioMinMaxScaler'] = scaler.fit_transform(df[['salario']]) # Aplica o MinMaxScaler à coluna 'salario', seguindo o mesmo processo da coluna 'idade'.\n",
        "\n",
        "min_max_scaler = MinMaxScaler(feature_range=(-1, 1)) # Cria uma nova instância do MinMaxScaler, mas desta vez configurando o intervalo de destino para [-1, 1].\n",
        "df['idadeMinMaxScaler_mm'] = min_max_scaler.fit_transform(df[['idade']]) # Aplica este MinMaxScaler configurado para o intervalo [-1, 1] à coluna 'idade', criando uma nova coluna.\n",
        "df['salarioMinMaxScaler_mm'] = min_max_scaler.fit_transform(df[['salario']]) # Aplica este MinMaxScaler configurado para o intervalo [-1, 1] à coluna 'salario', criando uma nova coluna.\n",
        "\n",
        "# Padronização - StandardScaler (Escalonamento para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler() # Cria uma instância do StandardScaler.\n",
        "df['idadeStandardScaler'] = scaler.fit_transform(df[['idade']]) # Aplica o StandardScaler à coluna 'idade'. `fit_transform` calcula a média e o desvio padrão da coluna e os usa para padronizar os dados.\n",
        "df['salarioStandardScaler'] = scaler.fit_transform(df[['salario']]) # Aplica o StandardScaler à coluna 'salario', padronizando-a.\n",
        "\n",
        "# Padronização RobustScaler (Escalonamento robusto a outliers)\n",
        "scaler = RobustScaler() # Cria uma instância do RobustScaler.\n",
        "df['idadeRobustScaler'] = scaler.fit_transform(df[['idade']]) # Aplica o RobustScaler à coluna 'idade'. `fit_transform` calcula a mediana e o Intervalo Interquartil (IQR) da coluna e os usa para escalar os dados, tornando-o menos sensível a *outliers*.\n",
        "df['salarioRobustScaler'] = scaler.fit_transform(df[['salario']]) # Aplica o RobustScaler à coluna 'salario', escalonando-a de forma robusta.\n",
        "\n",
        "print(df.head(15)) # Exibe as quinze primeiras linhas do DataFrame atualizado, que agora inclui todas as novas colunas com os dados escalonados e padronizados.\n",
        "\n",
        "print('MinMaxScaler (De 0 a 1):') # Imprime um título indicando as estatísticas para o MinMaxScaler no intervalo [0, 1].\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeMinMaxScaler'].min(), df['idadeMinMaxScaler'].max(), df['idadeMinMaxScaler'].mean(), df['idadeMinMaxScaler'].std())) # Imprime as estatísticas (mínimo, máximo, média, desvio padrão) da coluna 'idade' após a normalização MinMax [0, 1].\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioMinMaxScaler'].min(), df['salarioMinMaxScaler'].max(), df['salarioMinMaxScaler'].mean(), df['salarioMinMaxScaler'].std())) # Imprime as estatísticas da coluna 'salario' após a normalização MinMax [0, 1].\n",
        "\n",
        "print('\\nMinMaxScaler (De -1 a 1):') # Imprime um título para as estatísticas do MinMaxScaler no intervalo [-1, 1].\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeMinMaxScaler_mm'].min(), df['idadeMinMaxScaler_mm'].max(), df['idadeMinMaxScaler_mm'].mean(), df['idadeMinMaxScaler_mm'].std())) # Imprime as estatísticas da coluna 'idade' após a normalização MinMax [-1, 1].\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioMinMaxScaler_mm'].min(), df['salarioMinMaxScaler_mm'].max(), df['salarioMinMaxScaler_mm'].mean(), df['salarioMinMaxScaler_mm'].std())) # Imprime as estatísticas da coluna 'salario' após a normalização MinMax [-1, 1].\n",
        "\n",
        "print('\\nStandardScaler (Ajuste a média a 0 e desvio padrão a 1):') # Imprime um título para as estatísticas do StandardScaler.\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.18f} Std: {:.4f}'.format(df['idadeStandardScaler'].min(), df['idadeStandardScaler'].max(), df['idadeStandardScaler'].mean(), df['idadeStandardScaler'].std())) # Imprime as estatísticas da coluna 'idade' após a padronização StandardScaler. A média é exibida com alta precisão para mostrar que se aproxima de zero.\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.18f} Std: {:.4f}'.format(df['salarioStandardScaler'].min(), df['salarioStandardScaler'].max(), df['salarioStandardScaler'].mean(), df['salarioStandardScaler'].std())) # Imprime as estatísticas da coluna 'salario' após a padronização StandardScaler.\n",
        "\n",
        "print('\\nRobustScaler (Ajuste a média e IQR):') # Imprime um título para as estatísticas do RobustScaler.\n",
        "print('Idade - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['idadeRobustScaler'].min(), df['idadeRobustScaler'].max(), df['idadeRobustScaler'].mean(), df['idadeRobustScaler'].std())) # Imprime as estatísticas da coluna 'idade' após o escalonamento RobustScaler.\n",
        "print('Salário - Min: {:.4f} Max: {:.4f} Mean: {:.4f} Std: {:.4f}'.format(df['salarioRobustScaler'].min(), df['salarioRobustScaler'].max(), df['salarioRobustScaler'].mean(), df['salarioRobustScaler'].std())) # Imprime as estatísticas da coluna 'salario' após o escalonamento RobustScaler.\n",
        "```"
      ]
    }
  ]
}