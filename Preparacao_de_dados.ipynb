{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPscV33pWkyqksfX7l7b68Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaCaRego/JaCaRego/blob/main/Preparacao_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9TmqVXw9EpO2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b74cf915"
      },
      "source": [
        "### Resumo do Código: Análise Exploratória de Dados (AED)\n",
        "\n",
        "Este script Python utiliza a biblioteca **`pandas`** para realizar uma análise exploratória e pré-processamento de dados em um arquivo CSV de clientes. O objetivo principal é **preparar os dados para análise posterior**, o que inclui:\n",
        "\n",
        "1.  **Carregamento e Visualização Inicial:** Carrega o dataset 'clientes-v2.csv' e exibe as primeiras e últimas linhas para uma inspeção rápida.\n",
        "2.  **Tratamento de Datas:** Converte a coluna 'data' para o formato datetime, lidando com possíveis erros.\n",
        "3.  **Verificação de Qualidade dos Dados:** Realiza verificações importantes como:\n",
        "    *   `df.info()`: Para entender os tipos de dados e a presença de valores não nulos.\n",
        "    *   `df.isnull().sum()` e `df.isnull().mean()`: Para identificar e quantificar dados ausentes.\n",
        "    *   `df.dropna(inplace=True)`: Para remover linhas com valores nulos, garantindo a integridade dos dados.\n",
        "    *   `df.duplicated().sum()`: Para verificar a existência de registros duplicados.\n",
        "    *   `df.nunique()`: Para analisar a unicidade dos valores em cada coluna.\n",
        "    *   `df.describe()`: Para obter estatísticas descritivas (média, desvio padrão, quartis, etc.).\n",
        "4.  **Seleção de Features e Privacidade:** Filtra o DataFrame para incluir apenas colunas relevantes ('idade', 'data', 'estado', 'salario', 'nivel_educacao', 'numero_filhos', 'estado_civil', 'area_atuacao'), removendo informações potencialmente sensíveis ou irrelevantes para a análise subsequente.\n",
        "5.  **Exportação dos Dados Tratados:** Salva o DataFrame processado em um novo arquivo CSV, 'clientes-v2-tratados.csv', sem o índice do DataFrame original, para uso em etapas futuras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZSfSe3HD0Q3"
      },
      "outputs": [],
      "source": [
        "# Análise Exploratória de Dados (AED)\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('dados/clientes-v2.csv')\n",
        "\n",
        "print(df.head().to_string())\n",
        "print(df.tail().to_string())\n",
        "df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y', errors='coerce') # Pode ser tratado na preparação\n",
        "\n",
        "print('Verificação inicial: ')\n",
        "print(df.info())\n",
        "\n",
        "print('Analise de dados nulos:\\n', df.isnull().sum())\n",
        "print('% de dados nulos:\\n', df.isnull().mean() * 100)\n",
        "\n",
        "df.dropna(inplace=True) # Deletar todos campos nulos\n",
        "print('Confirma remoção de dados nulos:\\n', df.isnull().sum().sum()) # confirmar se foi deletado todos dados nulos\n",
        "\n",
        "print('Analise de dados duplicados:\\n', df.duplicated().sum())\n",
        "\n",
        "print('Analise de dados únicos:\\n', df.nunique())\n",
        "\n",
        "print('Estatística dos dados:\\n', df.describe()) # Estatística dos dados, quartil, std(desvio padrão)\n",
        "\n",
        "# Exclui dados sensíveis - identificar usuário (CPF, endereço) e pais(ja que é so Brasil), cria novo df\n",
        "df= df[['idade', 'data', 'estado', 'salario', 'nivel_educacao', 'numero_filhos', 'estado_civil', 'area_atuacao']]\n",
        "print(df.head().to_string())\n",
        "\n",
        "df.to_csv('dados/clientes-v2-tratados.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e88b2ecc"
      },
      "source": [
        "### Explicação Linha a Linha do Código\n",
        "\n",
        "Vamos detalhar cada parte do código para entender sua funcionalidade:\n",
        "\n",
        "1.  **`# Análise Exploratória de Dados (AED)`**\n",
        "    *   **Objetivo:** Um comentário para indicar o propósito geral do bloco de código.\n",
        "\n",
        "2.  **`import pandas as pd`**\n",
        "    *   **Comando:** `import pandas as pd`\n",
        "    *   **Objetivo:** Importa a biblioteca `pandas`, que é fundamental para manipulação e análise de dados em Python. O `as pd` cria um apelido para facilitar o uso da biblioteca (em vez de digitar `pandas` sempre, usamos `pd`).\n",
        "\n",
        "3.  **`df = pd.read_csv('dados/clientes-v2.csv')`**\n",
        "    *   **Comando:** `pd.read_csv()`\n",
        "    *   **Objetivo:** Carrega o arquivo CSV chamado 'clientes-v2.csv' (localizado na pasta 'dados') em um DataFrame do pandas. Um DataFrame é uma estrutura de dados tabular, semelhante a uma planilha ou tabela de banco de dados, onde cada coluna representa uma variável e cada linha um registro.\n",
        "\n",
        "4.  **`print(df.head().to_string())`**\n",
        "    *   **Comando:** `df.head()`, `to_string()`, `print()`\n",
        "    *   **Objetivo:** `df.head()` exibe as primeiras 5 linhas do DataFrame `df`. `to_string()` é usado para garantir que todas as colunas sejam impressas sem truncamento, e `print()` exibe isso no console. Isso serve para uma inspeção rápida dos dados após o carregamento.\n",
        "\n",
        "5.  **`print(df.tail().to_string())`**\n",
        "    *   **Comando:** `df.tail()`, `to_string()`, `print()`\n",
        "    *   **Objetivo:** Similar ao `head()`, mas `df.tail()` exibe as últimas 5 linhas do DataFrame. Ajuda a verificar a estrutura e o final do dataset.\n",
        "\n",
        "6.  **`df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y', errors='coerce')`**\n",
        "    *   **Comando:** `pd.to_datetime()`\n",
        "    *   **Objetivo:** Converte a coluna 'data' do DataFrame para o tipo de dado `datetime`. `format='%d/%m/%Y'` especifica o formato original da data (dia/mês/ano), e `errors='coerce'` trata quaisquer valores que não possam ser convertidos em datas, transformando-os em `NaT` (Not a Time), o que é útil para tratamento posterior.\n",
        "\n",
        "7.  **`print('Verificação inicial: ')`**\n",
        "    *   **Objetivo:** Imprime um cabeçalho para a próxima saída, indicando que uma verificação inicial será apresentada.\n",
        "\n",
        "8.  **`print(df.info())`**\n",
        "    *   **Comando:** `df.info()`\n",
        "    *   **Objetivo:** Fornece um resumo conciso do DataFrame, incluindo o número de entradas, o número de colunas, o tipo de dado de cada coluna, o número de valores não nulos em cada coluna e o uso de memória. É essencial para entender a estrutura e a qualidade inicial dos dados.\n",
        "\n",
        "9.  **`print('Analise de dados nulos:\\n', df.isnull().sum())`**\n",
        "    *   **Comando:** `df.isnull().sum()`\n",
        "    *   **Objetivo:** `df.isnull()` retorna um DataFrame booleano indicando `True` para valores nulos e `False` para não nulos. `sum()` então soma esses `True` (que são tratados como 1) para cada coluna, mostrando o total de valores nulos por coluna.\n",
        "\n",
        "10. **`print('% de dados nulos:\\n', df.isnull().mean() * 100)`**\n",
        "    *   **Comando:** `df.isnull().mean() * 100`\n",
        "    *   **Objetivo:** Calcula a porcentagem de valores nulos em cada coluna. `mean()` calcula a média dos valores booleanos (proporção de `True`), e multiplicar por 100 converte para porcentagem. Isso dá uma visão da gravidade dos dados ausentes.\n",
        "\n",
        "11. **`df.dropna(inplace=True)`**\n",
        "    *   **Comando:** `df.dropna()`\n",
        "    *   **Objetivo:** Remove linhas que contêm pelo menos um valor nulo (`NaN` ou `NaT`). `inplace=True` modifica o DataFrame original diretamente, sem a necessidade de atribuir o resultado a uma nova variável. É uma forma comum de lidar com dados ausentes quando a remoção é apropriada.\n",
        "\n",
        "12. **`print('Confirma remoção de dados nulos:\\n', df.isnull().sum().sum())`**\n",
        "    *   **Comando:** `df.isnull().sum().sum()`\n",
        "    *   **Objetivo:** Após remover os nulos, esta linha verifica se a remoção foi bem-sucedida. `df.isnull().sum()` soma os nulos por coluna, e o segundo `.sum()` soma esses totais, resultando no número total de nulos restantes no DataFrame. O esperado é 0.\n",
        "\n",
        "13. **`print('Analise de dados duplicados:\\n', df.duplicated().sum())`**\n",
        "    *   **Comando:** `df.duplicated().sum()`\n",
        "    *   **Objetivo:** `df.duplicated()` retorna uma série booleana indicando `True` para linhas que são duplicatas (exatamente iguais a uma linha anterior). `sum()` então conta o número total de linhas duplicadas no DataFrame.\n",
        "\n",
        "14. **`print('Analise de dados únicos:\\n', df.nunique())`**\n",
        "    *   **Comando:** `df.nunique()`\n",
        "    *   **Objetivo:** Retorna o número de valores únicos para cada coluna. Isso é útil para entender a variabilidade dos dados e identificar colunas com muitos ou poucos valores distintos (por exemplo, IDs que deveriam ser únicos, ou colunas categóricas com um número limitado de categorias).\n",
        "\n",
        "15. **`print('Estatística dos dados:\\n', df.describe())`**\n",
        "    *   **Comando:** `df.describe()`\n",
        "    *   **Objetivo:** Gera estatísticas descritivas para as colunas numéricas do DataFrame, como contagem, média, desvio padrão (`std`), valores mínimo e máximo, e os quartis (25%, 50% - mediana, e 75%). É fundamental para obter uma visão geral da distribuição dos dados.\n",
        "\n",
        "16. **`# Exclui dados sensíveis - identificar usuário (CPF, endereço) e pais(ja que é so Brasil), cria novo df`**\n",
        "    *   **Objetivo:** Comentário que explica a motivação para a próxima linha de código: remover informações que poderiam ser sensíveis ou irrelevantes para a análise.\n",
        "\n",
        "17. **`df= df[['idade', 'data', 'estado', 'salario', 'nivel_educacao', 'numero_filhos', 'estado_civil', 'area_atuacao']]`**\n",
        "    *   **Comando:** Seleção de colunas `df[[col1, col2, ...]]`\n",
        "    *   **Objetivo:** Cria um novo DataFrame `df` contendo apenas as colunas especificadas. Isso é um passo de engenharia de features/privacidade, removendo colunas que não são necessárias para a análise ou que contêm dados sensíveis que não devem ser expostos.\n",
        "\n",
        "18. **`print(df.head().to_string())`**\n",
        "    *   **Objetivo:** Exibe novamente as primeiras linhas do DataFrame após a seleção das colunas, para confirmar que as colunas indesejadas foram removidas.\n",
        "\n",
        "19. **`df.to_csv('dados/clientes-v2-tratados.csv', index=False)`**\n",
        "    *   **Comando:** `df.to_csv()`\n",
        "    *   **Objetivo:** Salva o DataFrame `df` processado em um novo arquivo CSV chamado 'clientes-v2-tratados.csv', localizado na pasta 'dados'. `index=False` impede que o índice do DataFrame seja escrito como uma coluna no arquivo CSV, evitando dados redundantes."
      ]
    }
  ]
}